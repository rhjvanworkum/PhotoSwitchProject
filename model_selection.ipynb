{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection \n",
    "\n",
    "In this notebook we show how we compared three different models:\n",
    "1. a random forest predictor\n",
    "2. a gaussian process regressor\n",
    "3. a Dense neural network\n",
    "\n",
    "And ultimately went with the gaussian process regressor as our surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import load_features_and_labels, load_property_data\n",
    "from src.random_forest import train_rf_model\n",
    "from src.gaussian_process import train_gp_model\n",
    "from src.neural_network import train_nn_model\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_features_and_labels('./processed_data/initial_dataset/mordred_descriptors.csv',\n",
    "                                './raw_data/photoswitches.csv',\n",
    "                                'e_iso_pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning training loop...\n",
      "\n",
      "mean R^2: 0.8613 +- 0.0072\n",
      "mean RMSE: 24.5489 +- 0.9114\n",
      "mean MAE: 15.5711 +- 0.5936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model, _, _ = train_rf_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning training loop...\n",
      "\n",
      "mean R^2: 0.9045 +- 0.0080\n",
      "mean RMSE: 20.1811 +- 0.8257\n",
      "mean MAE: 12.8562 +- 0.4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gp_model, _, _ = train_gp_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning training loop...\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 0.6554 - mae: 0.6554 - val_loss: 0.4015 - val_mae: 0.4015\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 4s 97ms/step - loss: 0.5845 - mae: 0.5845 - val_loss: 0.4995 - val_mae: 0.4995\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 5s 133ms/step - loss: 0.5581 - mae: 0.5581 - val_loss: 0.4369 - val_mae: 0.4369\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.5165 - mae: 0.5165 - val_loss: 0.5164 - val_mae: 0.5164\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 4s 111ms/step - loss: 0.4436 - mae: 0.4436 - val_loss: 0.3510 - val_mae: 0.3510\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.3208 - mae: 0.3208 - val_loss: 0.4733 - val_mae: 0.4733\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.3390 - mae: 0.3390 - val_loss: 0.3043 - val_mae: 0.3043\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 5s 119ms/step - loss: 0.2828 - mae: 0.2828 - val_loss: 0.3074 - val_mae: 0.3074\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.6780 - mae: 0.6780 - val_loss: 0.6401 - val_mae: 0.6401\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 2s 60ms/step - loss: 0.6099 - mae: 0.6099 - val_loss: 0.6014 - val_mae: 0.6014\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.5789 - mae: 0.5789 - val_loss: 0.4836 - val_mae: 0.4836\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 4s 102ms/step - loss: 0.4609 - mae: 0.4609 - val_loss: 0.5015 - val_mae: 0.5015\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3935 - mae: 0.3935 - val_loss: 0.2732 - val_mae: 0.2732\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 5s 118ms/step - loss: 0.3214 - mae: 0.3214 - val_loss: 0.3152 - val_mae: 0.3152\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 0.3152 - mae: 0.3152 - val_loss: 0.2511 - val_mae: 0.2511\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 3s 82ms/step - loss: 0.3203 - mae: 0.3203 - val_loss: 0.4236 - val_mae: 0.4236\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 4s 106ms/step - loss: 0.6016 - mae: 0.6016 - val_loss: 0.3641 - val_mae: 0.3641\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 4s 92ms/step - loss: 0.5450 - mae: 0.5450 - val_loss: 0.5295 - val_mae: 0.5295\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.5082 - mae: 0.5082 - val_loss: 0.5662 - val_mae: 0.5662\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 4s 89ms/step - loss: 0.4615 - mae: 0.4615 - val_loss: 0.4381 - val_mae: 0.4381\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.4082 - mae: 0.4082 - val_loss: 0.3337 - val_mae: 0.3337\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 5s 111ms/step - loss: 0.3994 - mae: 0.3994 - val_loss: 0.4183 - val_mae: 0.4183\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.3071 - mae: 0.3071 - val_loss: 0.2612 - val_mae: 0.2612\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 5s 120ms/step - loss: 0.2724 - mae: 0.2724 - val_loss: 0.2808 - val_mae: 0.2808\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 4s 102ms/step - loss: 0.6279 - mae: 0.6279 - val_loss: 0.6855 - val_mae: 0.6855\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.5707 - mae: 0.5707 - val_loss: 0.5379 - val_mae: 0.5379\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 5s 124ms/step - loss: 0.5987 - mae: 0.5987 - val_loss: 0.5468 - val_mae: 0.5468\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 0.4286 - mae: 0.4286 - val_loss: 0.5383 - val_mae: 0.5383\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 11s 257ms/step - loss: 0.4985 - mae: 0.4985 - val_loss: 0.4018 - val_mae: 0.4018\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.5176 - mae: 0.5176 - val_loss: 0.5479 - val_mae: 0.5479\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 7s 190ms/step - loss: 0.4059 - mae: 0.4059 - val_loss: 0.5088 - val_mae: 0.5088\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.4375 - mae: 0.4375 - val_loss: 0.2984 - val_mae: 0.2984\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.7214 - mae: 0.7214 - val_loss: 0.6810 - val_mae: 0.6810\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.6305 - mae: 0.6305 - val_loss: 0.7520 - val_mae: 0.7520\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 7s 174ms/step - loss: 0.5716 - mae: 0.5716 - val_loss: 0.5374 - val_mae: 0.5374\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 5s 134ms/step - loss: 0.4192 - mae: 0.4192 - val_loss: 0.3442 - val_mae: 0.3442\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 9s 224ms/step - loss: 0.3830 - mae: 0.3830 - val_loss: 0.7060 - val_mae: 0.7060\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 6s 150ms/step - loss: 0.4067 - mae: 0.4067 - val_loss: 0.3837 - val_mae: 0.3837\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 6s 160ms/step - loss: 0.3791 - mae: 0.3791 - val_loss: 0.3210 - val_mae: 0.3210\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 6s 148ms/step - loss: 0.3545 - mae: 0.3545 - val_loss: 0.4243 - val_mae: 0.4243\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 6s 142ms/step - loss: 0.6659 - mae: 0.6659 - val_loss: 0.6972 - val_mae: 0.6972\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.5684 - mae: 0.5684 - val_loss: 0.4947 - val_mae: 0.4947\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 6s 153ms/step - loss: 0.4371 - mae: 0.4371 - val_loss: 0.3988 - val_mae: 0.3988\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 6s 152ms/step - loss: 0.4699 - mae: 0.4699 - val_loss: 0.4137 - val_mae: 0.4137\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 6s 144ms/step - loss: 0.5275 - mae: 0.5275 - val_loss: 0.5548 - val_mae: 0.5548\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 0.4119 - mae: 0.4119 - val_loss: 0.3718 - val_mae: 0.3718\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 6s 161ms/step - loss: 0.3268 - mae: 0.3268 - val_loss: 0.3302 - val_mae: 0.3302\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 5s 134ms/step - loss: 0.3352 - mae: 0.3352 - val_loss: 0.5025 - val_mae: 0.5025\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 5s 130ms/step - loss: 0.8741 - mae: 0.8741 - val_loss: 1.4742 - val_mae: 1.4742\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 6s 139ms/step - loss: 0.7676 - mae: 0.7676 - val_loss: 0.6179 - val_mae: 0.6179\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.6344 - mae: 0.6344 - val_loss: 0.7336 - val_mae: 0.7336\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.5313 - mae: 0.5313 - val_loss: 0.4877 - val_mae: 0.4877\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 6s 155ms/step - loss: 0.5081 - mae: 0.5081 - val_loss: 0.4334 - val_mae: 0.4334\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 6s 142ms/step - loss: 0.3915 - mae: 0.3915 - val_loss: 0.3991 - val_mae: 0.3991\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 6s 154ms/step - loss: 0.4843 - mae: 0.4843 - val_loss: 0.4274 - val_mae: 0.4274\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.4479 - mae: 0.4479 - val_loss: 0.2799 - val_mae: 0.2799\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.6975 - mae: 0.6975 - val_loss: 0.7566 - val_mae: 0.7566\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 0.4981 - mae: 0.4981 - val_loss: 0.5934 - val_mae: 0.5934\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.3775 - mae: 0.3775 - val_loss: 0.4238 - val_mae: 0.4238\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.3680 - mae: 0.3680 - val_loss: 0.5860 - val_mae: 0.5860\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 4s 113ms/step - loss: 0.3960 - mae: 0.3960 - val_loss: 0.3281 - val_mae: 0.3281\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.2992 - mae: 0.2992 - val_loss: 0.3528 - val_mae: 0.3528\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 4s 97ms/step - loss: 0.3256 - mae: 0.3256 - val_loss: 0.5578 - val_mae: 0.5578\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 4s 96ms/step - loss: 0.3380 - mae: 0.3380 - val_loss: 0.3394 - val_mae: 0.3394\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 5s 132ms/step - loss: 0.7327 - mae: 0.7327 - val_loss: 0.9958 - val_mae: 0.9958\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.7411 - mae: 0.7411 - val_loss: 0.8960 - val_mae: 0.8960\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.5816 - mae: 0.5816 - val_loss: 0.5289 - val_mae: 0.5289\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.4400 - mae: 0.4400 - val_loss: 0.5941 - val_mae: 0.5941\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.3604 - mae: 0.3604 - val_loss: 0.4588 - val_mae: 0.4588\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.3142 - mae: 0.3142 - val_loss: 0.5676 - val_mae: 0.5676\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.3428 - mae: 0.3428 - val_loss: 0.4554 - val_mae: 0.4554\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 5s 131ms/step - loss: 0.3873 - mae: 0.3873 - val_loss: 0.6246 - val_mae: 0.6246\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 2s 61ms/step - loss: 0.7077 - mae: 0.7077 - val_loss: 0.7906 - val_mae: 0.7906\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 4s 92ms/step - loss: 0.5598 - mae: 0.5598 - val_loss: 0.4094 - val_mae: 0.4094\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.5252 - mae: 0.5252 - val_loss: 0.5641 - val_mae: 0.5641\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.5483 - mae: 0.5483 - val_loss: 0.7474 - val_mae: 0.7474\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.4535 - mae: 0.4535 - val_loss: 0.5064 - val_mae: 0.5064\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.4732 - mae: 0.4732 - val_loss: 0.2797 - val_mae: 0.2797\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.4594 - mae: 0.4594 - val_loss: 0.2952 - val_mae: 0.2952\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 5s 123ms/step - loss: 0.3916 - mae: 0.3916 - val_loss: 0.3042 - val_mae: 0.3042\n",
      "\n",
      "mean R^2: 0.6985 +- 0.0464\n",
      "mean RMSE: 35.6472 +- 3.3360\n",
      "mean MAE: 24.8292 +- 2.1071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model, _, _ = train_nn_model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "As we can see the GPR model fitted the data the best, which is why from now on we will continue working with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also look at the output of the gaussian process regression model in order to determine maybe some structural features that correspond with uncertainty in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18544/1530758517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msmiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmiles_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msmiles\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m   \u001b[0my_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0my_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\molbert\\lib\\site-packages\\gpflow\\models\\gpr.py\u001b[0m in \u001b[0;36mpredict_f\u001b[1;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m    163\u001b[0m         return self.posterior(posteriors.PrecomputeCacheType.NOCACHE).fused_predict_f(\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mXnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output_cov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         )\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\molbert\\lib\\site-packages\\gpflow\\posteriors.py\u001b[0m in \u001b[0;36mfused_predict_f\u001b[1;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m    144\u001b[0m         mean, cov = self._conditional_fused(\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mXnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output_cov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output_cov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         )\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_mean_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\molbert\\lib\\site-packages\\gpflow\\posteriors.py\u001b[0m in \u001b[0;36m_conditional_fused\u001b[1;34m(self, Xnew, full_cov, full_output_cov)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mKmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mKnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_cov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mKmn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mKmm_plus_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_noise_cov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlikelihood_variance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\molbert\\lib\\site-packages\\gpflow\\kernels\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, X2, full_cov, presliced)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpresliced\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfull_cov\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\molbert\\lib\\site-packages\\gpflow\\kernels\\base.py\u001b[0m in \u001b[0;36mslice\u001b[1;34m(self, X, X2)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# first lets get all the smiles strings\n",
    "df = pd.read_csv('./raw_data/photoswitches.csv')\n",
    "smiles_list = df['SMILES'].to_numpy()\n",
    "property_vals = load_property_data(df, 'e_iso_pi')\n",
    "invalid_indices = np.argwhere(np.isnan(property_vals))\n",
    "smiles_list = np.delete(np.array(smiles_list), invalid_indices)\n",
    "\n",
    "# and now calculate the variance associated with all those molecules\n",
    "y_vars = []\n",
    "for smiles in smiles_list:\n",
    "  _, var = gp_model.predict_f(smiles)\n",
    "  y_vars.append(var[0][0])\n",
    "y_vars = np.array(y_vars)\n",
    "  \n",
    "# so that we an rank them in a list\n",
    "ranked_confidence_list = np.argsort(y_vars, axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Least certain molecules: \\n')\n",
    "\n",
    "search_idx = ranked_confidence_list[:5]\n",
    "smiles = smiles_list[search_idx]\n",
    "\n",
    "print('Certainty/variance: ')\n",
    "print(y_vars[search_idx])\n",
    "\n",
    "image = Draw.MolsToGridImage([Chem.MolFromSmiles(smile) for smile in smiles], subImgSize=(250,250))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most certain molecules: \\n')\n",
    "\n",
    "search_idx = ranked_confidence_list[-5:]\n",
    "smiles = smiles_list[search_idx]\n",
    "\n",
    "print('Certainty/variance: ')\n",
    "print(y_vars[search_idx])\n",
    "\n",
    "image = Draw.MolsToGridImage([Chem.MolFromSmiles(smile) for smile in smiles], subImgSize=(250,250))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print('/n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "221fefb8189e6ba22c4f6b1c3cc4312d42e8d96d1fe9bcf4b50d8a271e4134ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('molbert': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
